services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    environment:
      # Configurações de timeout do Zookeeper
      ZK_TICK_TIME: 2000
      ZK_SYNC_LIMIT: 5
      ZK_MAX_CLIENT_CNXNS: 100
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
    networks:
      - data-pipeline-network
    healthcheck:
      test: echo ruok | nc localhost 2181 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    expose:
      - "9093"
    environment:
      # Configurações existentes
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "health-data:2:1,health-data-dlq:1:1"
      
      # Configurações de retenção e checkpoints
      KAFKA_LOG_RETENTION_MINUTES: "60" # Aumentado para 1 hora
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: "300000"
      
      # Configurações de memória
      KAFKA_HEAP_OPTS: "-Xmx768M -Xms512M"
      
      # Configurações de tópico
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      
      # Configurações de coordenação de grupo
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 10000
      KAFKA_GROUP_MIN_SESSION_TIMEOUT_MS: 120000
      KAFKA_GROUP_MAX_SESSION_TIMEOUT_MS: 300000
      
      # Configurações de transação
      KAFKA_TRANSACTION_MAX_TIMEOUT_MS: 900000
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      
      # Configurações de rede e performance
      KAFKA_NUM_NETWORK_THREADS: 4
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 1048576
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 1048576
      
      # Configurações de timeout
      KAFKA_CONNECTIONS_MAX_IDLE_MS: 600000
      KAFKA_METADATA_MAX_AGE_MS: 300000
      KAFKA_REQUEST_TIMEOUT_MS: 60000
    depends_on:
      zookeeper:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
    networks:
      - data-pipeline-network
    healthcheck:
      test: kafka-topics.sh --bootstrap-server localhost:9093 --list || exit 1
      interval: 30s
      timeout: 10s
      retries: 3

  kafdrop:
    image: obsidiandynamics/kafdrop
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: kafka:9093
      JVM_OPTS: "-Xms128M -Xmx256M"
      SERVER_SERVLET_CONTEXTPATH: "/"
    depends_on:
      - kafka
    deploy:
      resources:
        limits:
          memory: 384M
          cpus: '0.5'
    networks:
      - data-pipeline-network

  jobmanager:
    image: flink:1.17.0-java11
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        state.backend: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
        # Configurações de checkpoint otimizadas
        execution.checkpointing.interval: 60000
        execution.checkpointing.min-pause: 30000
        execution.checkpointing.timeout: 300000
        execution.checkpointing.max-concurrent-checkpoints: 1
        execution.checkpointing.externalized-checkpoint-retention: RETAIN_ON_CANCELLATION
        execution.checkpointing.mode: EXACTLY_ONCE
        
        # Configurações de retry e recovery básicas
        restart-strategy: failure-rate
        restart-strategy.failure-rate.max-failures-per-interval: 3
        restart-strategy.failure-rate.failure-rate-interval: 5 min
        restart-strategy.failure-rate.delay: 10 s
        S
        # Configurações de rede
        taskmanager.network.detailed-metrics: true
        taskmanager.network.request-backoff.initial: 100
        taskmanager.network.request-backoff.max: 10000
        taskmanager.network.retries: 10
        # Configurações de restart
        restart-strategy: fixed-delay
        restart-strategy.fixed-delay.attempts: 10
        restart-strategy.fixed-delay.delay: 10s
    volumes:
      - flink-checkpoints:/opt/flink/checkpoints
      - ./jobmanager-entrypoint.sh:/custom-entrypoint.sh
    entrypoint: ["/custom-entrypoint.sh"]
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
    networks:
      - data-pipeline-network
    hostname: jobmanager
    healthcheck:
      test: curl -f localhost:8081/overview || exit 1
      interval: 30s
      timeout: 10s
      retries: 3

  taskmanager:
    image: flink:1.17.0-java11
    depends_on:
      jobmanager:
        condition: service_healthy
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        taskmanager.rpc.address: taskmanager
        jobmanager.rpc.address: jobmanager
        state.backend: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
    scale: 2
    volumes:
      - flink-checkpoints:/opt/flink/checkpoints
      - ./jobmanager-entrypoint.sh:/custom-entrypoint.sh
    entrypoint: ["/custom-entrypoint.sh"]
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
    networks:
      - data-pipeline-network

  job-submitter:
    image: flink:1.17.0-java11
    depends_on:
      jobmanager:
        condition: service_healthy
    volumes:
      - ./health-data-pipeline/target:/opt/flink/job
    command: >
      /bin/bash -c "
      echo 'Waiting for JobManager to be ready...' &&
      until curl -s jobmanager:8081/overview > /dev/null; do
        echo 'Waiting for JobManager...' &&
        sleep 5;
      done &&
      echo 'JobManager is ready. Submitting job...' &&
      flink run -d -m jobmanager:8081 /opt/flink/job/health-data-pipeline-1.0-SNAPSHOT.jar"
    networks:
      - data-pipeline-network

  postgres:
    image: postgres:latest
    environment:
      POSTGRES_USER: health_user
      POSTGRES_PASSWORD: health_password
      POSTGRES_DB: health_db
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 768MB
      POSTGRES_WORK_MEM: 32MB
      POSTGRES_MAINTENANCE_WORK_MEM: 64MB
      POSTGRES_MAX_CONNECTIONS: 100
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
    networks:
      - data-pipeline-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U health_user"]
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  data-pipeline-network:
    driver: bridge
    name: data-pipeline-network

volumes:
  postgres-data:
  flink-checkpoints:
    driver: local